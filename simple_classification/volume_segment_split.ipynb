{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import noisereduce as nr\n",
    "import torch as tr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, sr = torchaudio.load('../normalized/sensor_1.wav')\n",
    "x2, sr = torchaudio.load('../normalized/sensor_2.wav')\n",
    "x3, sr = torchaudio.load('../normalized/sensor_3.wav')\n",
    "X = tr.concat([x1, x2, x3], dim=0)\n",
    "\n",
    "N = len(x1[0])\n",
    "n = 3\n",
    "tt = tr.arange(N) / sr\n",
    "ii = tr.linspace(0, N, n, dtype=tr.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_or(a, w):\n",
    "    w = int(w)\n",
    "    y = tr.zeros(a.shape)\n",
    "    for i in range(w, a.shape[0]-w , w//4):\n",
    "        y[i-w:i+w] = True in a[i-w:i+w]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(samples, window_size):\n",
    "    # samples: (..., time)\n",
    "    y = []\n",
    "    for j in range(samples.shape[0]):\n",
    "        for i in range(-window_size//2, window_size//2):\n",
    "            y.append(tr.roll(samples[j], i, dims=0))\n",
    "    return tr.mean(tr.row_stack(y), dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windows(length, window_size):\n",
    "    for j in range(0, length, window_size):\n",
    "        yield j, j + window_size - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Range Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://seaindia.in/blogs/human-voice-frequency-range/\n",
    "X = torchaudio.functional.lowpass_biquad(X, sr, 3500)\n",
    "X = torchaudio.functional.highpass_biquad(X, sr, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amplitude Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "C = []\n",
    "ease_l = 10000\n",
    "threshold = 1.3\n",
    "\n",
    "for x in X: # for each sensor\n",
    "    E = tr.sqrt(tr.mean(x**2)) # Calculate a baseline\n",
    "    c = tr.abs(x) > E * threshold\n",
    "    c = long_or(c, .25 * sr) # expand acceptance bands\n",
    "\n",
    "    ease_in = tr.where(tr.diff(c) > 0)[0]\n",
    "    ease_out = tr.where(tr.diff(c) < 0)[0]\n",
    "    \n",
    "    for i in ease_in:\n",
    "        ii = tr.arange(max(0, i-ease_l), min(i+ease_l, len(c)))\n",
    "        c[ii] = (ii - ii[0]) / len(ii)\n",
    "    \n",
    "    for i in ease_out:\n",
    "        ii = tr.arange(max(0, i-ease_l), min(i+ease_l, len(c)))\n",
    "        c[ii] = 1 - (ii - ii[0]) / len(ii)\n",
    "\n",
    "    C.append(c)\n",
    "    # plt.fill_between(tt, c, alpha=.3)\n",
    "    # plt.yticks([])\n",
    "C = tr.vstack(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusion\n",
    "Use volume discriminator to separate high volume and low volume sounds (segmentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation\n",
    "X_high = X * C\n",
    "X_low = X * (1 - C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross apply noise segments and use moving average as fusion function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.save('high_segment.wav', X_high, sr)\n",
    "torchaudio.save('low_segment.wav', X_low, sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
